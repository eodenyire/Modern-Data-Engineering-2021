# Modern-Data-Engineering-2021

i. CS fundamentals</b></p>
Basic terminal usage 
Data structures & algorithms 
APIs 
REST 
Structured vs unstructured data
Serialisation
Linux 
CLI
Vim
Shell scripting
Cronjobs
How does the computer work? 
How does the Internet work? 
Git — Version control 
Math & statistics basics 
Note: Git is used for tracking changes in source code and coordinating work among programmers. In your day to day work you will use Git server as a service like GitHub, GitLab or Bitbucket.

Learn a programming language</b></p>
Python 
Java 
Scala
Go
Note: Learn how to write clean, extensibile code. Spend some time understanding programming paradigms (functional vs. OOP) and best practices (design patterns, YAGNI, stateful vs stateless applications). Get familiar with an IDE or code editor like VSCode.

Testing</b></p>

Unit testing 
Integration testing 
Functional testing 
Database fundamentals

SQL </b></p>
Normalisation 
ACID transactions 
CAP theorem 
OLTP vs OLAP 
Horizontal vs vertical scaling 
Dimensional modeling 
Relational databases</b></p>

MySQL
PostgreSQL
MariaDB
Amazon Aurora
Non-relational databases</b></p>

Document databases
MongoDB 
Elasticsearch 
Apache CouchDB
Azure CormosDB
Wide column databases
Apache Cassandra 
Apache HBase 
Google Cloud Bigtable 
Graph databases
Neo4j
Amazon Neptune
Key-value stores
Redis 
Memcached
Amazon DynamoDB 
Note: Understand the difference between Document, Wide column, Graph and Key-value NoSQL databases. We recommend mastering one database from each category.

Data warehouses</b></p>

Snowflake 
Presto
Apache Hive
Apache Impala
Amazon Redshift 
Google BigQuery 
Azure Synapse
ClickHouse

Object storage</b></p>

AWS S3 
Azure Blob Storage
Google Cloud Storage
Apache Ozone

Cluster computing fundamentals</b></p>

Apache Hadoop 
HDFS 
MapReduce 
Lambda & Kappa architectures
Managed Hadoop 
Amazon EMR
Google Dataproc
Azure Data Lake
Note: Most modern data processing frameworks are based on Apache Hadoop and MapReduce to some extent. Understanding these concepts can help you learn modern data processing frameworks much quicker.

Data processing</b></p>
Batch
Apache Pig 
Apache Arrow
data build tool 
Hybrid
Apache Spark 
Apache Beam 
Apache Flin
Apache NiFi
Streaming
Apache Kafka 
Apache Storm 
Apache Samza
Amazon Kinesis
Note: Hybrid frameworks are able to process both batch and streaming data. Batch data processing is often done by analytical data warehouse applications. See Data warehouses section for more.

Messaging</b></p>

RabbitMQ 
Apache ActiveMQ
Amazon SNS & SQS
Google PubSub
Azure Service Bus

Workflow scheduling</b></p>

Apache Airflow 
Google Composer
Apache Oozie
Luigi
Note: Cloud Composer is a managed Apache Airflow service on Google Cloud Platform.

Monitoring and observability for data pipelines</b></p>

Prometheus
Datadog 
Sentry 
Monte Carlo
Datafold
Soda Data
StatsD
Networking

Protocols</b></p>
HTTP / HTTPS
TCP
SSH
IP
DNS
Firewalls 
VPN 
VPC 
Infrastructure as Code

Containers</b></p>
Docker 
LXC
Container orchestration
Kubernetes 
Docker Swarm
Apache Mesos
Google Kubernetes Engine (GKE)
Infrastructure provisioning
Terraform
Pulumi
AWS CDK 
CI/CD

GitHub Actions </b></p>
Jenkins 
Identity and access management

Active Directory 
Azure Active Directory
Data security & privacy

Legal compliance </b></p>
Encryption 
Key management 
Data governance & integrity

Note: Data engineers often work closely with Data scientists, Data analysts and Machine Learning engineers. It’s good to have a basic understanding of the tools they use.

Visualise data</b></p>

Tableau 
Looker
Grafana 
Jupyter Notebook 
Microsoft Power BI
Machine Learning fundamentals

Terminology</b></p>
Supervised vs unsupervised learning
Classification vs regression
Evaluation metrics
scikit-learn 
Tensorflow 
Keras 
PyTorch 
Machine Learning Ops

Tensorflow Extended (TFX) 
Kubeflow 
MLflow
Amazon SageMaker
Google Cloud AI Platform
Note: Keep learning...
